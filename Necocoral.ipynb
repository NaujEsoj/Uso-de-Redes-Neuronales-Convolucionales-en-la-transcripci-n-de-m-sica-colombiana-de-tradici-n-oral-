{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchaudio\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullPipelineDataset(Dataset):\n",
    "    def __init__(self, wav_folder, separated_folder, midi_folder, sr=22050, n_mels=128, fs_midi=50,\n",
    "                 fixed_full_length=200, fixed_midi_length=50):\n",
    "        self.wav_folder = wav_folder\n",
    "        self.separated_folder = separated_folder\n",
    "        self.midi_folder = midi_folder\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.fs_midi = fs_midi\n",
    "        self.fixed_full_length = fixed_full_length\n",
    "        self.fixed_midi_length = fixed_midi_length\n",
    "        \n",
    "        self.wav_files = sorted([f for f in os.listdir(wav_folder) if f.lower().endswith('.wav')])\n",
    "        self.mel_transform = torchaudio.transforms.MelSpectrogram(sample_rate=sr, n_mels=n_mels)\n",
    "        \n",
    "    def pad_or_crop_tensor(self, tensor, target_length):\n",
    "        current_length = tensor.size(-1)\n",
    "        if current_length > target_length:\n",
    "            return tensor[..., :target_length]\n",
    "        elif current_length < target_length:\n",
    "            pad_amount = target_length - current_length\n",
    "            return F.pad(tensor, (0, pad_amount))\n",
    "        else:\n",
    "            return tensor\n",
    "\n",
    "    def midi_to_piano_roll(self, midi_path):\n",
    "        pm = pretty_midi.PrettyMIDI(midi_path)\n",
    "        piano_roll = pm.get_piano_roll(fs=self.fs_midi)  # [128, T]\n",
    "        piano_roll = (piano_roll > 0).astype(np.float32)\n",
    "        return piano_roll\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.wav_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wav_filename = self.wav_files[idx]\n",
    "        base_name = os.path.splitext(wav_filename)[0]\n",
    "        wav_path = os.path.join(self.wav_folder, wav_filename)\n",
    "        waveform, sr = torchaudio.load(wav_path)\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "        full_spec = self.mel_transform(waveform)\n",
    "        full_spec = full_spec.log2().clamp(min=-10)\n",
    "        full_spec = self.pad_or_crop_tensor(full_spec, self.fixed_full_length)\n",
    "        \n",
    "        instruments = ['vocals', 'bass', 'drums', 'other']\n",
    "        separated_specs = {}\n",
    "        sep_folder = os.path.join(self.separated_folder, base_name)\n",
    "        for inst in instruments:\n",
    "            sep_path = os.path.join(sep_folder, f\"{inst}.wav\")\n",
    "            if not os.path.exists(sep_path):\n",
    "                sep_spec = torch.zeros(1, self.n_mels, self.fixed_full_length)\n",
    "            else:\n",
    "                sep_wave, _ = torchaudio.load(sep_path)\n",
    "                if sep_wave.shape[0] > 1:\n",
    "                    sep_wave = sep_wave.mean(dim=0, keepdim=True)\n",
    "                sep_spec = self.mel_transform(sep_wave)\n",
    "                sep_spec = sep_spec.log2().clamp(min=-10)\n",
    "                sep_spec = self.pad_or_crop_tensor(sep_spec, self.fixed_full_length)\n",
    "            separated_specs[inst] = sep_spec\n",
    "\n",
    "        midi_piano_rolls = {}\n",
    "        midi_subfolder = os.path.join(self.midi_folder, base_name)\n",
    "        for inst in instruments:\n",
    "            midi_path = os.path.join(midi_subfolder, f\"{inst}.mid\")\n",
    "            if not os.path.exists(midi_path):\n",
    "                raise FileNotFoundError(f\"MIDI no encontrado: {midi_path}\")\n",
    "            pr = self.midi_to_piano_roll(midi_path)\n",
    "            pr_tensor = torch.tensor(pr)\n",
    "            pr_tensor = self.pad_or_crop_tensor(pr_tensor, self.fixed_midi_length)\n",
    "            midi_piano_rolls[inst] = pr_tensor\n",
    "\n",
    "        return full_spec, separated_specs, midi_piano_rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "class FullPipelineCNN(nn.Module):\n",
    "    def __init__(self, output_dims, input_shape):\n",
    "        super(FullPipelineCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        _, n_mels, tiempo = input_shape\n",
    "        fm_height = n_mels // 4\n",
    "        fm_width  = tiempo // 4\n",
    "\n",
    "        self.fc_common = nn.Linear(32 * fm_height * fm_width, 512)\n",
    "        self.branch_vocals = nn.Linear(512, output_dims['vocals'])\n",
    "        self.branch_bass   = nn.Linear(512, output_dims['bass'])\n",
    "        self.branch_drums  = nn.Linear(512, output_dims['drums'])\n",
    "        self.branch_other  = nn.Linear(512, output_dims['other'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc_common(x))\n",
    "        vocals = torch.sigmoid(self.branch_vocals(x))\n",
    "        bass   = torch.sigmoid(self.branch_bass(x))\n",
    "        drums  = torch.sigmoid(self.branch_drums(x))\n",
    "        other  = torch.sigmoid(self.branch_other(x))\n",
    "        return {'vocals': vocals, 'bass': bass, 'drums': drums, 'other': other}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluación\n",
    "def evaluate_model(model, dataloader, criterion, device='cpu', return_loss=False):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_batches = 0\n",
    "    instruments = ['vocals', 'bass', 'drums', 'other']\n",
    "    preds_all = {inst: [] for inst in instruments}\n",
    "    targets_all = {inst: [] for inst in instruments}\n",
    "    with torch.no_grad():\n",
    "        for full_spec, separated_specs, midi_piano_rolls in dataloader:\n",
    "            full_spec = full_spec.to(device)\n",
    "            outputs = model(full_spec)\n",
    "            batch_loss = 0.0\n",
    "            for inst in instruments:\n",
    "                target = midi_piano_rolls[inst].view(outputs[inst].size()).to(device)\n",
    "                batch_loss += criterion(outputs[inst], target)\n",
    "                preds_all[inst].append(outputs[inst].cpu())\n",
    "                targets_all[inst].append(target.cpu())\n",
    "            total_loss += batch_loss.item()\n",
    "            total_batches += 1\n",
    "    avg_loss = total_loss / total_batches\n",
    "    print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "    for inst in instruments:\n",
    "        preds = torch.cat(preds_all[inst], dim=0).view(-1).numpy()\n",
    "        targs = torch.cat(targets_all[inst], dim=0).view(-1).numpy()\n",
    "        preds_bin = (preds >= 0.5).astype(int)\n",
    "        acc = accuracy_score(targs, preds_bin)\n",
    "        rec = recall_score(targs, preds_bin, zero_division=0)\n",
    "        f1 = f1_score(targs, preds_bin, zero_division=0)\n",
    "        print(f\"{inst.capitalize()} -> Accuracy: {acc:.4f}, Recall: {rec:.4f}, F1 Score: {f1:.4f}\")\n",
    "    if return_loss:\n",
    "        return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamiento, Early Stopping\n",
    "def train_model(model, dataloader, optimizer, criterion, num_epochs=10, device='cpu', val_loader=None, early_stop_patience=5, min_delta=0.001):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for full_spec, separated_specs, midi_piano_rolls in dataloader:\n",
    "            full_spec = full_spec.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(full_spec)\n",
    "            loss = 0.0\n",
    "            for inst in ['vocals', 'bass', 'drums', 'other']:\n",
    "                target = midi_piano_rolls[inst].view(outputs[inst].size()).to(device)\n",
    "                loss += criterion(outputs[inst], target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_loss = running_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_loss:.4f}\")\n",
    "        if val_loader is not None:\n",
    "            print(\"Validation metrics:\")\n",
    "            val_loss = evaluate_model(model, val_loader, criterion, device=device, return_loss=True)\n",
    "            if best_val_loss - val_loss > min_delta:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "            print(f\"Validation Loss: {val_loss:.4f} | Best: {best_val_loss:.4f} | Patience: {epochs_no_improve}/{early_stop_patience}\")\n",
    "            if epochs_no_improve >= early_stop_patience:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Goliath\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 1.9237\n",
      "Validation metrics:\n",
      "Average Loss: 0.2274\n",
      "Vocals -> Accuracy: 0.9848, Recall: 0.2609, F1 Score: 0.1100\n",
      "Bass -> Accuracy: 0.9861, Recall: 0.1868, F1 Score: 0.0337\n",
      "Drums -> Accuracy: 0.9868, Recall: 0.3051, F1 Score: 0.0719\n",
      "Other -> Accuracy: 0.9816, Recall: 0.1066, F1 Score: 0.0500\n",
      "Validation Loss: 0.2274 | Best: 0.2274 | Patience: 0/5\n",
      "Epoch 2/20 - Train Loss: 0.0972\n",
      "Validation metrics:\n",
      "Average Loss: 0.0977\n",
      "Vocals -> Accuracy: 0.9968, Recall: 0.1976, F1 Score: 0.3086\n",
      "Bass -> Accuracy: 0.9983, Recall: 0.1868, F1 Score: 0.2222\n",
      "Drums -> Accuracy: 0.9985, Recall: 0.3475, F1 Score: 0.4409\n",
      "Other -> Accuracy: 0.9952, Recall: 0.0533, F1 Score: 0.0921\n",
      "Validation Loss: 0.0977 | Best: 0.0977 | Patience: 0/5\n",
      "Epoch 3/20 - Train Loss: 0.0641\n",
      "Validation metrics:\n",
      "Average Loss: 0.0749\n",
      "Vocals -> Accuracy: 0.9969, Recall: 0.2451, F1 Score: 0.3615\n",
      "Bass -> Accuracy: 0.9985, Recall: 0.1648, F1 Score: 0.2256\n",
      "Drums -> Accuracy: 0.9984, Recall: 0.2373, F1 Score: 0.3333\n",
      "Other -> Accuracy: 0.9954, Recall: 0.0313, F1 Score: 0.0585\n",
      "Validation Loss: 0.0749 | Best: 0.0749 | Patience: 0/5\n",
      "Epoch 4/20 - Train Loss: 0.0443\n",
      "Validation metrics:\n",
      "Average Loss: 0.0628\n",
      "Vocals -> Accuracy: 0.9971, Recall: 0.2292, F1 Score: 0.3602\n",
      "Bass -> Accuracy: 0.9985, Recall: 0.2747, F1 Score: 0.3165\n",
      "Drums -> Accuracy: 0.9985, Recall: 0.2627, F1 Score: 0.3735\n",
      "Other -> Accuracy: 0.9955, Recall: 0.0219, F1 Score: 0.0423\n",
      "Validation Loss: 0.0628 | Best: 0.0628 | Patience: 0/5\n",
      "Epoch 5/20 - Train Loss: 0.0400\n",
      "Validation metrics:\n",
      "Average Loss: 0.0599\n",
      "Vocals -> Accuracy: 0.9971, Recall: 0.2451, F1 Score: 0.3758\n",
      "Bass -> Accuracy: 0.9985, Recall: 0.2747, F1 Score: 0.3165\n",
      "Drums -> Accuracy: 0.9985, Recall: 0.2881, F1 Score: 0.3953\n",
      "Other -> Accuracy: 0.9955, Recall: 0.0408, F1 Score: 0.0762\n",
      "Validation Loss: 0.0599 | Best: 0.0599 | Patience: 0/5\n",
      "Epoch 6/20 - Train Loss: 0.0384\n",
      "Validation metrics:\n",
      "Average Loss: 0.0584\n",
      "Vocals -> Accuracy: 0.9971, Recall: 0.2292, F1 Score: 0.3636\n",
      "Bass -> Accuracy: 0.9986, Recall: 0.2637, F1 Score: 0.3200\n",
      "Drums -> Accuracy: 0.9986, Recall: 0.3390, F1 Score: 0.4444\n",
      "Other -> Accuracy: 0.9954, Recall: 0.0564, F1 Score: 0.1003\n",
      "Validation Loss: 0.0584 | Best: 0.0584 | Patience: 0/5\n",
      "Epoch 7/20 - Train Loss: 0.0370\n",
      "Validation metrics:\n",
      "Average Loss: 0.0597\n",
      "Vocals -> Accuracy: 0.9971, Recall: 0.2372, F1 Score: 0.3670\n",
      "Bass -> Accuracy: 0.9985, Recall: 0.2747, F1 Score: 0.3165\n",
      "Drums -> Accuracy: 0.9986, Recall: 0.3644, F1 Score: 0.4674\n",
      "Other -> Accuracy: 0.9955, Recall: 0.0313, F1 Score: 0.0595\n",
      "Validation Loss: 0.0597 | Best: 0.0584 | Patience: 1/5\n",
      "Epoch 8/20 - Train Loss: 0.0366\n",
      "Validation metrics:\n",
      "Average Loss: 0.0601\n",
      "Vocals -> Accuracy: 0.9971, Recall: 0.2332, F1 Score: 0.3688\n",
      "Bass -> Accuracy: 0.9985, Recall: 0.2747, F1 Score: 0.3268\n",
      "Drums -> Accuracy: 0.9985, Recall: 0.2797, F1 Score: 0.3837\n",
      "Other -> Accuracy: 0.9954, Recall: 0.0251, F1 Score: 0.0475\n",
      "Validation Loss: 0.0601 | Best: 0.0584 | Patience: 2/5\n",
      "Epoch 9/20 - Train Loss: 0.0363\n",
      "Validation metrics:\n",
      "Average Loss: 0.0609\n",
      "Vocals -> Accuracy: 0.9971, Recall: 0.2372, F1 Score: 0.3704\n",
      "Bass -> Accuracy: 0.9985, Recall: 0.2637, F1 Score: 0.3097\n",
      "Drums -> Accuracy: 0.9986, Recall: 0.3220, F1 Score: 0.4270\n",
      "Other -> Accuracy: 0.9955, Recall: 0.0313, F1 Score: 0.0592\n",
      "Validation Loss: 0.0609 | Best: 0.0584 | Patience: 3/5\n",
      "Epoch 10/20 - Train Loss: 0.0361\n",
      "Validation metrics:\n",
      "Average Loss: 0.0616\n",
      "Vocals -> Accuracy: 0.9971, Recall: 0.2372, F1 Score: 0.3727\n",
      "Bass -> Accuracy: 0.9985, Recall: 0.2857, F1 Score: 0.3355\n",
      "Drums -> Accuracy: 0.9985, Recall: 0.3136, F1 Score: 0.4181\n",
      "Other -> Accuracy: 0.9955, Recall: 0.0784, F1 Score: 0.1359\n",
      "Validation Loss: 0.0616 | Best: 0.0584 | Patience: 4/5\n",
      "Epoch 11/20 - Train Loss: 0.0358\n",
      "Validation metrics:\n",
      "Average Loss: 0.0610\n",
      "Vocals -> Accuracy: 0.9971, Recall: 0.2332, F1 Score: 0.3688\n",
      "Bass -> Accuracy: 0.9985, Recall: 0.2747, F1 Score: 0.3205\n",
      "Drums -> Accuracy: 0.9985, Recall: 0.2542, F1 Score: 0.3636\n",
      "Other -> Accuracy: 0.9955, Recall: 0.0063, F1 Score: 0.0124\n",
      "Validation Loss: 0.0610 | Best: 0.0584 | Patience: 5/5\n",
      "Early stopping triggered!\n",
      "Test metrics:\n",
      "Average Loss: 0.0396\n",
      "Vocals -> Accuracy: 0.9983, Recall: 0.3279, F1 Score: 0.4563\n",
      "Bass -> Accuracy: 0.9987, Recall: 0.4133, F1 Score: 0.5415\n",
      "Drums -> Accuracy: 0.9983, Recall: 0.2069, F1 Score: 0.2970\n",
      "Other -> Accuracy: 0.9972, Recall: 0.0086, F1 Score: 0.0169\n"
     ]
    }
   ],
   "source": [
    "# Parámetros, ruta\n",
    "wav_folder = \"F:\\\\TG MINTA\\\\Audios\\\\dataset\\\\wav\"\n",
    "separated_folder = \"F:\\\\TG MINTA\\\\Audios\\\\dataset\\\\separated\"\n",
    "midi_folder = \"F:\\\\TG MINTA\\\\Audios\\\\dataset\\\\midi\"\n",
    "\n",
    "sr = 22050\n",
    "n_mels = 128\n",
    "fs_midi = 50\n",
    "fixed_full_length = 200   # Frames espectrograma\n",
    "fixed_midi_length = 50    # Frames piano roll\n",
    "input_shape = (1, n_mels, fixed_full_length)\n",
    "output_dims = {\n",
    "    'vocals': 128 * fixed_midi_length,\n",
    "    'bass': 128 * fixed_midi_length,\n",
    "    'drums': 128 * fixed_midi_length,\n",
    "    'other': 128 * fixed_midi_length\n",
    "}\n",
    "\n",
    "dataset = FullPipelineDataset(wav_folder, separated_folder, midi_folder,\n",
    "                              sr, n_mels, fs_midi, fixed_full_length, fixed_midi_length)\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "model = FullPipelineCNN(output_dims, input_shape)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 20\n",
    "\n",
    "model = train_model(model, train_loader, optimizer, criterion, num_epochs=num_epochs, device=device, val_loader=val_loader, early_stop_patience=5, min_delta=0.001)\n",
    "print(\"Test metrics:\")\n",
    "evaluate_model(model, test_loader, criterion, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
